{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: The new table is red. The blue table is broken.\n",
      "Pre-processed words: ['the', 'new', 'table', 'is', 'red', 'the', 'blue', 'table', 'is', 'broken']\n",
      "Document size: 10\n",
      "Vocabulary: {'red', 'is', 'table', 'new', 'blue', 'the', 'broken'}\n",
      "Vocabulary size: 7\n"
     ]
    }
   ],
   "source": [
    "text = \"The new table is red. The blue table is broken.\"\n",
    "words_processed = ['the', 'new', 'table', 'is', 'red', 'the', 'blue', 'table', 'is', 'broken']\n",
    "vocabulary = set() # Create an empty set\n",
    "for word in words_processed: # Iterate through available words\n",
    "    vocabulary.add(word) # Add word to set\n",
    "print(\"Document:\",text)\n",
    "print(\"Pre-processed words:\",words_processed)\n",
    "print(\"Document size:\",len(words_processed))\n",
    "print(\"Vocabulary:\",vocabulary)\n",
    "print(\"Vocabulary size:\",len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Unigrams (1-Grams)\n",
    "### 4.2.1 Compute unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 7 samples and 10 outcomes> \n",
      "\n",
      "{'blue': 1, 'broken': 1, 'is': 2, 'new': 1, 'red': 1, 'table': 2, 'the': 2}\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist  # Import the FreqDist function from NLTK\n",
    "tf = FreqDist(words_processed)  # Compute term frequency of words\n",
    "print(tf, \"\\n\")\n",
    "vocabulary = sorted(vocabulary)  # Sort alphabetically for better presentation\n",
    "unigrams = dict()  # Create empty dictionary for unigrams\n",
    "\n",
    "for word in vocabulary:\n",
    "    unigrams[word] = tf[word]\n",
    "print(unigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Unigram probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram probabilities: {'blue': 0.1, 'broken': 0.1, 'is': 0.2, 'new': 0.1, 'red': 0.1, 'table': 0.2, 'the': 0.2}\n"
     ]
    }
   ],
   "source": [
    "total_words = len(words_processed)  # Compute total words in corpus\n",
    "unigram_probabilities = dict()  # Create empty dictionary for unigram probabilities\n",
    "for word in unigrams:\n",
    "    unigram_probabilities[word] = unigrams[word] / \\\n",
    "        total_words  # Compute P(w_n)\n",
    "print(\"Unigram probabilities:\", unigram_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Sentence probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x000002B13E4C3EB0>, {'blue': 0.1, 'broken': 0.1, 'is': 0.2, 'new': 0.1, 'red': 0.1, 'table': 0.2, 'the': 0.2}) \n",
      "\n",
      "P(the new table is red)= 0.000080\n",
      "P(the black table)= 0.000000\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "# Create a dictionary that will return 0 for unknown words\n",
    "pw = defaultdict(lambda: 0, unigram_probabilities)\n",
    "print(pw, \"\\n\")\n",
    "p_text1 = pw[\"the\"]*pw[\"new\"]*pw[\"table\"]*pw[\"is\"]*pw[\"red\"]\n",
    "p_text2 = pw[\"the\"]*pw[\"black\"]*pw[\"table\"]\n",
    "print(\"P(the new table is red)= %f\" % p_text1)\n",
    "print(\"P(the black table)= %f\" % p_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(unknown)=0.000100\n",
      "\n",
      "Unigram probabilities (Add-lambda smoothing):\n",
      " {'blue': 0.10002997901468971, 'broken': 0.10002997901468971, 'is': 0.1999600279804137, 'new': 0.10002997901468971, 'red': 0.10002997901468971, 'table': 0.1999600279804137, 'the': 0.1999600279804137} \n",
      "\n",
      "P(the new table is red)= 0.000080\n",
      "P(the black table)= 0.000004\n"
     ]
    }
   ],
   "source": [
    "V = len(vocabulary)  # Compute words in vocabulary\n",
    "total_words = len(words_processed)  # Compute total words in corpus\n",
    "l = 0.001  # Define lambda for Add-lambda smoothing\n",
    "# Compute the probability of unknown words using add-lambda smoothing\n",
    "p_unknown = (0 + l) / ((l*V) + total_words)\n",
    "print(\"P(unknown)=%f\\n\" % p_unknown)\n",
    "# Create empty dictionary for unigram probabilities\n",
    "unigram_probabilities_addl = dict()\n",
    "for word in unigrams:\n",
    "    unigram_probabilities_addl[word] = (\n",
    "        unigrams[word] + l) / (total_words + (l*V))  # Compute P(w_n)\n",
    "print(\"Unigram probabilities (Add-lambda smoothing):\\n\",\n",
    "      unigram_probabilities_addl, \"\\n\")\n",
    "# Create a dictionary that will return p_unknown for unknown words\n",
    "plw = defaultdict(lambda: p_unknown, unigram_probabilities_addl)\n",
    "pl_text1 = plw[\"the\"]*plw[\"new\"]*plw[\"table\"]*plw[\"is\"]*plw[\"red\"]\n",
    "pl_text2 = plw[\"the\"]*plw[\"black\"]*plw[\"table\"]\n",
    "print(\"P(the new table is red)= %f\" % pl_text1)\n",
    "print(\"P(the black table)= %f\" % pl_text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Bigrams (2-Grams)\n",
    "### 4.3.1 Compute bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', 'new')\n",
      "('new', 'table')\n",
      "('table', 'is')\n",
      "('is', 'red')\n",
      "('red', 'the')\n",
      "('the', 'blue')\n",
      "('blue', 'table')\n",
      "('table', 'is')\n",
      "('is', 'broken')\n",
      "\n",
      "Unique bigrams:\n",
      " {('the', 'blue'), ('blue', 'table'), ('new', 'table'), ('red', 'the'), ('the', 'new'), ('is', 'red'), ('table', 'is'), ('is', 'broken')}\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "text = \"The new table is red. The blue table is broken.\"\n",
    "words_processed = ['the', 'new', 'table', 'is',\n",
    "                   'red', 'the', 'blue', 'table', 'is', 'broken']\n",
    "bigrams = ngrams(words_processed, 2)  # Compute the bigrams in the text\n",
    "bigrams_unique = set()  # Create empty set for unique bigrams\n",
    "for bigram in bigrams:\n",
    "    print(bigram)\n",
    "    bigrams_unique.add(bigram)  # Add bigram to set\n",
    "print(\"\\nUnique bigrams:\\n\", bigrams_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(('the', 'new'), 1), (('new', 'table'), 1), (('table', 'is'), 2), (('is', 'red'), 1), (('red', 'the'), 1), (('the', 'blue'), 1), (('blue', 'table'), 1), (('is', 'broken'), 1)])\n"
     ]
    }
   ],
   "source": [
    "bigrams = ngrams(words_processed,2) # Compute the bigrams in the text\n",
    "bigram_freq = FreqDist(bigrams).items() # Compute frequency distribution for all the bigrams in the text\n",
    "print(bigram_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram counts: defaultdict(<function <lambda> at 0x000002B103081870>, {'</s>': 2, '<s>': 2, 'blue': 1, 'broken': 1, 'is': 2, 'new': 1, 'red': 1, 'table': 2, 'the': 2}) \n",
      "\n",
      "Bigram counts: dict_items([(('<s>', 'the'), 2), (('the', 'new'), 1), (('new', 'table'), 1), (('table', 'is'), 2), (('is', 'red'), 1), (('red', '</s>'), 1), (('</s>', '<s>'), 1), (('the', 'blue'), 1), (('blue', 'table'), 1), (('is', 'broken'), 1), (('broken', '</s>'), 1)]) \n",
      "\n",
      "P(<s> the new table is red </s>)= 0.250000\n",
      "P(<s> the black table </s>)= 0.000000\n"
     ]
    }
   ],
   "source": [
    "text = \"The new table is red. The blue table is broken.\"\n",
    "# Add tokens indicating the start and end of a sentence in the respective position\n",
    "text2 = \"<s> The new table is red. </s> <s> The blue table is broken. </s>\"\n",
    "words_processed = ['<s>', 'the', 'new', 'table', 'is', 'red', '</s>', '<s>', 'the', 'blue', 'table',\n",
    "                   'is', 'broken', '</s>']\n",
    "vocabulary = set()  # Create an empty set\n",
    "for word in words_processed:  # Iterate through available words\n",
    "    vocabulary.add(word)  # Add word to set\n",
    "tf = FreqDist(words_processed)  # Compute term frequency of words\n",
    "vocabulary = sorted(vocabulary)  # Sort alphabetically for better presentation\n",
    "ugf = dict()  # Create empty dictionary for unigram counts\n",
    "for word in vocabulary:\n",
    "    ugf[word] = tf[word]\n",
    "# Create a dictionary that will return 0 for unknown unigrams\n",
    "ugf = defaultdict(lambda: 0, ugf)\n",
    "print(\"Unigram counts:\", ugf, \"\\n\")\n",
    "bigrams = ngrams(words_processed, 2)  # Compute the bigrams in the text\n",
    "# Compute frequency distribution for all the bigrams in the text\n",
    "bigram_freq = FreqDist(bigrams).items()\n",
    "print(\"Bigram counts:\", bigram_freq, \"\\n\")\n",
    "# Create a dictionary that will return 0 for unknown bigrams\n",
    "bgf = defaultdict(lambda: 0, bigram_freq)\n",
    "\n",
    "\n",
    "# Create function to compute bigram probability\n",
    "def p_big(bigram, bigram_frequencies, unigram_frequencies):\n",
    "    if (bigram_frequencies[bigram] == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return bigram_frequencies[bigram] / unigram_frequencies[bigram[0]]\n",
    "\n",
    "\n",
    "p_text1 = p_big(('<s>', 'the'), bgf, ugf)*p_big(('the', 'new'), bgf, ugf)*p_big(('new', 'table'), bgf,\n",
    "                                                                                ugf)*p_big(('table', 'is'), bgf, ugf)*p_big(('is', 'red'), bgf, ugf)*p_big(('red', '</s>'), bgf, ugf)\n",
    "p_text2 = p_big(('<s>', 'the'), bgf, ugf)*p_big(('the', 'black'), bgf, ugf) * \\\n",
    "    p_big(('black', 'table'), bgf, ugf)*p_big(('table', '</s>'), bgf, ugf)\n",
    "print(\"P(<s> the new table is red </s>)= %f\" % p_text1)\n",
    "print(\"P(<s> the black table </s>)= %f\" % p_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram counts: dict_items([(('<s>', '<s>'), 2), (('<s>', 'the'), 2), (('the', 'new'), 1), (('new', 'table'), 1), (('table', 'is'), 2), (('is', 'red'), 1), (('red', '</s>'), 1), (('</s>', '</s>'), 2), (('</s>', '<s>'), 1), (('the', 'blue'), 1), (('blue', 'table'), 1), (('is', 'broken'), 1), (('broken', '</s>'), 1)]) \n",
      "\n",
      "Trigram counts: dict_items([(('<s>', '<s>', 'the'), 2), (('<s>', 'the', 'new'), 1), (('the', 'new', 'table'), 1), (('new', 'table', 'is'), 1), (('table', 'is', 'red'), 1), (('is', 'red', '</s>'), 1), (('red', '</s>', '</s>'), 1), (('</s>', '</s>', '<s>'), 1), (('</s>', '<s>', '<s>'), 1), (('<s>', 'the', 'blue'), 1), (('the', 'blue', 'table'), 1), (('blue', 'table', 'is'), 1), (('table', 'is', 'broken'), 1), (('is', 'broken', '</s>'), 1), (('broken', '</s>', '</s>'), 1)]) \n",
      "\n",
      "P(<s> <s> the new table is red </s> </s>)= 0.250000\n",
      "P(<s> <s> the black table </s> </s>)= 0.000000\n"
     ]
    }
   ],
   "source": [
    "text = \"The new table is red. The blue table is broken.\"\n",
    "# Add tokens indicating the start and end of a sentence in the respective position\n",
    "text3 = \"<s> <s> The new table is red. </s> </s> <s> <s> The blue table is broken. </s> </s>\"\n",
    "words_processed = ['<s>', '<s>', 'the', 'new', 'table', 'is', 'red', '</s>', '</s>', '<s>', '<s>', 'the',\n",
    "                   'blue', 'table', 'is', 'broken', '</s>', '</s>']\n",
    "bigrams = ngrams(words_processed, 2)  # Compute the bigrams in the text\n",
    "# Compute frequency distribution for all the bigrams in the\n",
    "bigram_freq = FreqDist(bigrams).items()\n",
    "text\n",
    "print(\"Bigram counts:\", bigram_freq, \"\\n\")\n",
    "trigrams = ngrams(words_processed, 3)  # Compute the trigrams in the text\n",
    "# Compute frequency distribution for all the trigrams in the text\n",
    "trigram_freq = FreqDist(trigrams).items()\n",
    "print(\"Trigram counts:\", trigram_freq, \"\\n\")\n",
    "# Create a dictionary that will return 0 for unknown bigrams\n",
    "bgf = defaultdict(lambda: 0, bigram_freq)\n",
    "# Create a dictionary that will return 0 for unknown\n",
    "tgf = defaultdict(lambda: 0, trigram_freq)\n",
    "trigrams\n",
    "\n",
    "\n",
    "# Create function to compute trigram probability\n",
    "def p_trig(trigram, trigram_frequencies, bigram_frequencies):\n",
    "    if (trigram_frequencies[trigram] == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return trigram_frequencies[trigram] / bigram_frequencies[(trigram[0], trigram[1])]\n",
    "\n",
    "\n",
    "p_text1 = p_trig(('<s>', '<s>', 'the'), tgf, bgf)*p_trig(('<s>', 'the', 'new'), tgf, bgf)*p_trig(('the', 'new', 'table'), tgf, bgf)*p_trig(('new',\n",
    "                                                                                                                                            'table', 'is'), tgf, bgf)*p_trig(('table', 'is', 'red'), tgf, bgf)*p_trig(('is', 'red', '</s>'), tgf, bgf)*p_trig(('red', '</s>', '</s>'), tgf, bgf)\n",
    "p_text2 = p_trig(('<s>', '<s>', 'the'), tgf, bgf)*p_trig(('<s>', 'the', 'black'), tgf, bgf)*p_trig(('the', 'black',\n",
    "                                                                                                    'table'), tgf, bgf)*p_trig(('black', 'table', '</s>'), tgf, bgf)*p_trig(('table', '</s>', '</s>'), tgf, bgf)\n",
    "print(\"P(<s> <s> the new table is red </s> </s>)= %f\" % p_text1)\n",
    "print(\"P(<s> <s> the black table </s> </s>)= %f\" % p_text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Exercises\n",
    "### Exercise 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test cases passed!\n"
     ]
    }
   ],
   "source": [
    "def get_sentence_probability_unigram(words_list, unigram_frequencies):\n",
    "    total_words = sum(unigram_frequencies.values())\n",
    "    sentence_probability = 1\n",
    "    for word in words_list:\n",
    "        word_probability = unigram_frequencies.get(word, 0) / total_words\n",
    "        sentence_probability *= word_probability\n",
    "    return sentence_probability\n",
    "\n",
    "\n",
    "def test_get_sentence_probability_unigram():\n",
    "    # Test case 1\n",
    "    words_list = ['the', 'new', 'table', 'is', 'red']\n",
    "    unigram_frequencies = {'the': 2, 'new': 1, 'table': 1, 'is': 1, 'red': 1}\n",
    "    expected_probability = 0.00032  # Updated expected probability\n",
    "    get_sentence_probability_unigram(\n",
    "        words_list, unigram_frequencies) == expected_probability\n",
    "\n",
    "    # Test case 2\n",
    "    words_list = ['the', 'blue', 'table', 'is', 'broken']\n",
    "    unigram_frequencies = {'the': 2, 'blue': 1,\n",
    "                           'table': 1, 'is': 1, 'broken': 1}\n",
    "    expected_probability = 0.00032  # Updated expected probability\n",
    "    get_sentence_probability_unigram(\n",
    "        words_list, unigram_frequencies) == expected_probability\n",
    "\n",
    "    # Test case 3\n",
    "    words_list = ['the', 'new', 'table', 'is', 'blue']\n",
    "    unigram_frequencies = {'the': 2, 'new': 1, 'table': 1, 'is': 1, 'red': 1}\n",
    "    expected_probability = 0\n",
    "    get_sentence_probability_unigram(\n",
    "        words_list, unigram_frequencies) == expected_probability\n",
    "\n",
    "    # Add more test cases as needed\n",
    "\n",
    "    print(\"All test cases passed!\")\n",
    "\n",
    "\n",
    "test_get_sentence_probability_unigram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
