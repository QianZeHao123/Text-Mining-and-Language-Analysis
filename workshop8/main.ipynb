{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./news.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alltext</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear. Daniel Greenfiel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy. U...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             alltext  label\n",
       "0  You Can Smell Hillary’s Fear. Daniel Greenfiel...      1\n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...      1\n",
       "2  Kerry to go to Paris in gesture of sympathy. U...      0\n",
       "3  Bernie supporters on Twitter erupt in anger ag...      1\n",
       "4  The Battle of New York: Why This Primary Matte...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set value of label to 1 if FAKE, else to 0 for REAL\n",
    "df['label'] = (df['label'] == 'FAKE').astype('int')\n",
    "# Concatenate title and text into column alltext\n",
    "df['alltext'] = df['title'] + \". \" + df['text']\n",
    "# Transform the dataset to contain only the label and all text columns\n",
    "df = df.reindex(columns=['alltext', 'label'])\n",
    "df.head(5)  # Show first 5 rows in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 6327\n",
      "Labels: 6327 \n",
      "\n",
      "you can smell hillary’s fear. daniel greenfield, a shillman journalism fellow at the freedom center, is a new york writer focusing on radical islam. \n",
      "in the final stretch of the election, hillary rodham clinton has gone to war with the fbi. \n",
      "the word “unprecedented” has been thrown around so often this election that it ought to be retired. but it’s still unprecedented for the nominee of a major political party to go war with the fbi. \n",
      "but that’s exactly what hillary and her people have done. coma patients just waking up now and watching an hour of cnn from their hospital beds would assume that fbi director james comey is hillary’s opponent in this election. \n",
      "the fbi is under attack by everyone from obama to cnn. hillary’s people have circulated a letter attacking comey. there are currently more media hit pieces lambasting him than targeting trump. it wouldn’t be too surprising if the clintons or their allies were to start running attack ads against the fbi. \n",
      "the fbi’s leadership is bei\n"
     ]
    }
   ],
   "source": [
    "# Remove texts that are less than 50 characters long\n",
    "df.drop(df[df.alltext.str.len() < 50].index, inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def convert_to_lowercase(text):  # Convert all characters to lowercase\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "# Convert text to lowercase\n",
    "df['alltext'] = df['alltext'].apply(convert_to_lowercase)\n",
    "print(\"Samples:\", len(df['alltext']))\n",
    "print(\"Labels:\", len(df['label']), \"\\n\")\n",
    "# Print the first 1000 characters of the first text as an example\n",
    "print(df['alltext'].iloc[0][0:1000])\n",
    "# Save processed dataset to csv file\n",
    "df.to_csv('fakenews_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split dataset into 30% for test and 70% for training\n",
    "train, test = train_test_split(df, test_size=0.30, random_state=42)\n",
    "X_train = train[\"alltext\"].values  # Get the documents for training\n",
    "Y_train = train[\"label\"].values  # Get the labels for training\n",
    "X_test = test[\"alltext\"].values  # Get the documents for testing\n",
    "Y_test = test[\"label\"].values  # Get the labels for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Reduce the number of shown warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\QianZ\\miniconda3\\envs\\DS\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\QianZ\\miniconda3\\envs\\DS\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\QianZ\\miniconda3\\envs\\DS\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "Vocabulary size: 5000 words\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import TextVectorization\n",
    "# The maximum number of words to be used (most frequent)\n",
    "MAX_VOCABULARY_WORDS = 5000\n",
    "# Number of words in each text. Sequence length to pad the outputs to.\n",
    "MAX_SEQUENCE_LENGTH = 200\n",
    "EMBEDDING_DIM = 10  # Size of the word embedding to be used\n",
    "# Create a preprocessing layer which maps text features to integer sequences\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=MAX_VOCABULARY_WORDS,  # Maximum size of the vocabulary for this layer\n",
    "    output_mode='int',  # Represent each word in the vocabulary with an integer\n",
    "    output_sequence_length=MAX_SEQUENCE_LENGTH)  # Pad the sequence length to size MAX_SEQUENCE_LENGTH\n",
    "# Computes a vocabulary of string terms from tokens in a dataset.\n",
    "vectorize_layer.adapt(X_train)\n",
    "vocabulary = vectorize_layer.get_vocabulary()  # Get the vocabulary\n",
    "print(\"Vocabulary size: \" + str(len(vocabulary)) + \" words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MyLSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVe  (None, 200)               0         \n",
      " ctorization)                                                    \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 200, 10)           50000     \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 200, 32)           3456      \n",
      " al)                                                             \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 32)                6272      \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59761 (233.44 KB)\n",
      "Trainable params: 59761 (233.44 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, Bidirectional\n",
    "model = Sequential(name=\"MyLSTM\")\n",
    "model.add(Input(shape=(1,), dtype=tf.string))\n",
    "\n",
    "model.add(vectorize_layer)\n",
    "model.add(Embedding(input_dim=MAX_VOCABULARY_WORDS,  # Size of the vocabulary\n",
    "                    output_dim=EMBEDDING_DIM,  # Size of the word embedding\n",
    "                    input_length=MAX_SEQUENCE_LENGTH))  # Length of input sequences\n",
    "# Set return_sequences=True if you want additional LSTM layer\n",
    "model.add(Bidirectional(LSTM(16, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(16, go_backwards=True, dropout=0.2)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()  # Print model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.01\n",
    "opt = Adam(learning_rate=LEARNING_RATE) # Initialise Adam optimiser with a leanring rate of 0.01\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy']) # Initialise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\QianZ\\miniconda3\\envs\\DS\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "63/63 [==============================] - 9s 78ms/step - loss: 0.3946 - accuracy: 0.8148 - val_loss: 0.2725 - val_accuracy: 0.8781\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 4s 64ms/step - loss: 0.1491 - accuracy: 0.9458 - val_loss: 0.2451 - val_accuracy: 0.8962\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 4s 62ms/step - loss: 0.0620 - accuracy: 0.9817 - val_loss: 0.3103 - val_accuracy: 0.9007\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 4s 64ms/step - loss: 0.0235 - accuracy: 0.9940 - val_loss: 0.3653 - val_accuracy: 0.8916\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 4s 62ms/step - loss: 0.0114 - accuracy: 0.9975 - val_loss: 0.4159 - val_accuracy: 0.8984\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 4s 63ms/step - loss: 0.0058 - accuracy: 0.9992 - val_loss: 0.4716 - val_accuracy: 0.9052\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 4s 63ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.4690 - val_accuracy: 0.8984\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 4s 63ms/step - loss: 0.0284 - accuracy: 0.9920 - val_loss: 0.4413 - val_accuracy: 0.8871\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 4s 63ms/step - loss: 0.0405 - accuracy: 0.9849 - val_loss: 0.4698 - val_accuracy: 0.8962\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 4s 64ms/step - loss: 0.0153 - accuracy: 0.9955 - val_loss: 0.7008 - val_accuracy: 0.8668\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early = EarlyStopping(monitor=\"val_accuracy\", patience=4,\n",
    "                      restore_best_weights=True, mode=\"auto\")\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "                    validation_split=0.1,  # Use 10% of training data for validation\n",
    "                    callbacks=[early]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
